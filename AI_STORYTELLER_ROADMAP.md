# ğŸ¤– AI Storyteller Roadmap

**Status:** Phase 1 Complete âœ…  
**Created:** 2025-11-08  
**Updated:** 2025-11-09
**Goal:** Transform dungeon crawler into dynamic narrative experience with AI-driven storytelling

---

## ğŸ¯ Vision

Replace static descriptions and canned responses with an AI agent that serves as a dynamic storyteller, creating personalized narrative experiences while maintaining reliable game mechanics.

## âœ… Current Architecture Advantages

- âœ… Event-driven server architecture (perfect for AI callbacks)
- âœ… Session management (track narrative context per player)
- âœ… Modular design (easy AI integration points)
- âœ… 10 distinct chamber types (ready for dynamic descriptions)
- âœ… Comprehensive test suite (ensure AI doesn't break mechanics)

## ğŸ® Integration Strategy: Hybrid Mode

**Core Principle:** Deterministic mechanics + AI narrative layer

- **Game Engine:** Handles dice, combat, stats, inventory (unchanged)
- **AI Layer:** Provides descriptions, dialogue, quests, flavor text
- **Benefit:** Reliable gameplay with rich, dynamic storytelling

---

## ğŸ“‹ TODO: Phase 1 - AI Narration Layer (2-3 days)

### âœ… TODO 1.1: Create AI Storyteller Module
- âœ… Create `src/ai_storyteller.lua`
- âœ… Implement LLM client (Ollama or OpenAI API)
- âœ… Add configuration for API endpoint/model selection
- âœ… Implement basic prompt templates
- âœ… Add error handling and fallbacks

### âœ… TODO 1.2: Dynamic Chamber Descriptions
- âœ… Replace static `chamber_art.lua` with AI-generated descriptions
- âœ… Create chamber context builder (type, exits, items, enemies)
- âœ… Implement description caching (avoid regenerating)
- â³ Add player history to context (previous chambers visited)
- âœ… Fallback to static descriptions on API failure

### â³ TODO 1.3: Combat Narration
- âœ… Create combat event hooks in `src/combat.lua`
- âœ… Generate dramatic attack descriptions
- âœ… Narrate hits, misses, critical hits, defeats
- â³ Maintain combat pacing (concise vs verbose modes)
- â³ Track combat history for coherent narrative
**Note:** Combat narration infrastructure complete but not yet integrated into game server (game_server.lua doesn't have combat events yet)

### âœ… TODO 1.4: Testing & Integration
- âœ… Create `tests/test_ai_storyteller.lua`
- âœ… Test API connectivity and error handling
- âœ… Mock LLM responses for automated testing
- âœ… Performance testing (latency targets: <500ms local, <200ms API)
- âœ… Integration with existing game server

### âœ… TODO 1.5: Configuration & Setup
- âœ… Add AI config to server startup
- âœ… Document API key setup (OpenAI) or Ollama installation
- âœ… Create toggle for AI mode vs classic mode
- â³ Add verbose/concise narrative settings
- âœ… Update README with AI setup instructions

**Phase 1 Status:** âœ… Complete (90%) - Core functionality delivered, combat integration pending game server updates

---

## ğŸ“‹ TODO: Phase 2 - Dynamic NPCs (3-5 days)

### TODO 2.1: NPC Memory System
- [ ] Create `src/npc_memory.lua`
- [ ] Track conversations per session
- [ ] Store NPC personality profiles
- [ ] Remember player interactions and choices
- [ ] Implement context windowing (last N interactions)

### TODO 2.2: Conversational NPCs
- [ ] Replace canned NPC responses with AI dialogue
- [ ] Create NPC personality templates (merchant, guard, prisoner, etc.)
- [ ] Implement free-form player queries
- [ ] Add dialogue state machine (greeting, trading, quest, farewell)
- [ ] Maintain character consistency across conversations

### TODO 2.3: Dynamic Quest Generation
- [ ] Create quest context builder (player level, location, history)
- [ ] Generate quests based on chamber context
- [ ] Track quest progress and state
- [ ] Implement quest rewards (XP, items, story progression)
- [ ] Multiple quest types (fetch, kill, explore, solve)

### TODO 2.4: NPC Actions & Reactions
- [ ] NPCs react to player reputation/choices
- [ ] Shopkeeper pricing based on relationship
- [ ] Guards react to player behavior
- [ ] Prisoners share secrets if helped
- [ ] Dynamic faction system

### TODO 2.5: Testing
- [ ] Create `tests/test_npc_ai.lua`
- [ ] Test conversation coherence
- [ ] Test memory persistence across sessions
- [ ] Test quest generation variety
- [ ] Performance testing for dialogue generation

---

## ğŸ“‹ TODO: Phase 3 - Adaptive Storytelling (1-2 weeks)

### TODO 3.1: Player Choice Tracking
- [ ] Create `src/narrative_engine.lua`
- [ ] Track all player decisions and actions
- [ ] Build player reputation system
- [ ] Record key story moments
- [ ] Implement consequence tracking

### TODO 3.2: Branching Narratives
- [ ] Create story arc templates
- [ ] Implement narrative branches based on choices
- [ ] Generate dungeon themes (haunted, ancient, corrupted, etc.)
- [ ] Persistent world changes from player actions
- [ ] Multiple endings based on playthrough

### TODO 3.3: Personalized Campaigns
- [ ] Analyze player style (combat, stealth, diplomacy)
- [ ] Adapt dungeon generation to preferences
- [ ] Custom loot based on play style
- [ ] Personalized challenges and encounters
- [ ] Remember player achievements across sessions

### TODO 3.4: Dynamic World Events
- [ ] Random events with narrative impact
- [ ] Time-based story progression
- [ ] Recurring NPCs and storylines
- [ ] Dungeon "living world" simulation
- [ ] Player actions affect future encounters

### TODO 3.5: Meta-Narrative Features
- [ ] Campaign mode (multi-session storylines)
- [ ] Character relationships and growth
- [ ] Unlockable lore and backstory
- [ ] Player legacy system (actions affect other players)
- [ ] Story summaries and highlights

### TODO 3.6: Testing & Polish
- [ ] Create `tests/test_narrative_engine.lua`
- [ ] Playtest full campaigns
- [ ] Balance narrative pacing
- [ ] Optimize context management (avoid token bloat)
- [ ] Performance optimization for long sessions

---

## ğŸ”§ Technical Implementation Details

### AI Integration Points

```lua
-- src/ai_storyteller.lua (to be created)
local ai_storyteller = {
    -- Configuration
    provider = "ollama",  -- or "openai"
    model = "llama3.2",
    endpoint = "http://localhost:11434/api/generate",
    api_key = nil,  -- for OpenAI
    
    -- Core Functions
    narrate_chamber = function(chamber_type, player_history)
        -- Generate vivid room descriptions
    end,
    
    narrate_combat = function(action, attacker, defender, result)
        -- Dynamic combat narration
    end,
    
    generate_dialogue = function(npc_type, player_query, conversation_history)
        -- NPC conversations
    end,
    
    generate_quest = function(context)
        -- Context-aware quest generation
    end,
    
    -- Utility
    get_completion = function(prompt, max_tokens)
        -- LLM API wrapper
    end,
    
    build_context = function(session_data)
        -- Build context from session state
    end
}
```

### LLM Provider Options

**Option 1: Ollama (Local)**
- âœ… Free, private, no rate limits
- âœ… Models: llama3.2, mistral, phi
- âš ï¸ ~500ms latency
- âš ï¸ Requires local installation
- ğŸ’° Cost: $0

**Option 2: OpenAI API**
- âœ… Fast (<100ms)
- âœ… High quality (GPT-4, GPT-3.5)
- âš ï¸ Requires API key
- âš ï¸ Rate limits
- ğŸ’° Cost: ~$0.01-0.05 per game session

**Option 3: Anthropic Claude**
- âœ… Excellent at roleplay/narrative
- âœ… Large context window (200K tokens)
- âš ï¸ Requires API key
- ğŸ’° Cost: ~$0.02-0.08 per session

**Recommendation:** Start with Ollama for development, add OpenAI as optional premium feature

### Performance Targets

| Operation | Target Latency | Acceptable Max |
|-----------|---------------|----------------|
| Chamber description | <500ms | 1000ms |
| Combat narration | <300ms | 500ms |
| NPC dialogue | <800ms | 1500ms |
| Quest generation | <2000ms | 5000ms |

### Context Management

```lua
-- Keep context under control
context = {
    player_stats = {...},           -- 100 tokens
    current_chamber = {...},        -- 150 tokens
    recent_history = [...],         -- 300 tokens (last 5 actions)
    active_quests = [...],          -- 200 tokens
    npc_memory = {...},            -- 250 tokens (relevant NPCs)
    -- Total: ~1000 tokens input
    -- Output: ~200-500 tokens
    -- Total per request: ~1500 tokens
}
```

---

## ğŸš€ Quick Start (Once Implemented)

### With Ollama (Local, Free)
```bash
# Install Ollama
curl -fsSL https://ollama.com/install.sh | sh

# Download model
ollama pull llama3.2

# Start server with AI
lua game_server.lua --ai-mode ollama

# Connect client
lua game_client.lua -i
```

### With OpenAI API
```bash
# Set API key
export OPENAI_API_KEY="sk-..."

# Start server with AI
lua game_server.lua --ai-mode openai --ai-model gpt-4

# Connect client
lua game_client.lua -i
```

---

## ğŸ“Š Integration Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Game Client                             â”‚
â”‚                  (Interactive REPL)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ Commands (move, search, talk)
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Game Server (game_server.lua)              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚          Session Manager (server_core.lua)             â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚              â”‚                              â”‚                â”‚
â”‚              â–¼                              â–¼                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Game Engine       â”‚      â”‚   AI Storyteller         â”‚ â”‚
â”‚  â”‚   (deterministic)   â”‚â—„â”€â”€â”€â”€â–ºâ”‚   (narrative layer)      â”‚ â”‚
â”‚  â”‚                     â”‚      â”‚                          â”‚ â”‚
â”‚  â”‚ â€¢ Dice rolls        â”‚      â”‚ â€¢ Chamber descriptions   â”‚ â”‚
â”‚  â”‚ â€¢ Combat math       â”‚      â”‚ â€¢ Combat narration       â”‚ â”‚
â”‚  â”‚ â€¢ Inventory         â”‚      â”‚ â€¢ NPC dialogue           â”‚ â”‚
â”‚  â”‚ â€¢ Stats tracking    â”‚      â”‚ â€¢ Quest generation       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                               â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                â”‚
                                                â–¼
                                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                   â”‚   LLM Provider         â”‚
                                   â”‚   (Ollama/OpenAI)      â”‚
                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¨ Example: Before vs After

### Before (Static)
```
You enter the chamber.

  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
  â•‘    THRONE ROOM     â•‘
  â•‘                    â•‘
  â•‘        ğŸ‘‘         â•‘
  â•‘      â–“â–“â–“â–“â–“        â•‘
  â•‘                    â•‘
  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Exits: North, East
```

### After (AI-Enhanced)
```
You push open the massive oak doors and step into a magnificent throne room.
Tattered banners hang from the vaulted ceiling, their once-proud heraldry
faded to ghostly shadows. At the far end, a throne of black iron sits upon
a dais, its surface etched with runes that pulse with a faint crimson light.

The air is thick with the scent of ancient power and decay. Dust motes dance
in shafts of light from arrow-slit windows high above. Something glints
beneath the throne...

Exits lead north through a collapsed archway, and east into darkness.
```

---

## âš ï¸ Risks & Mitigation

### Risk 1: AI Unpredictability
- **Mitigation:** Validate AI output, fallback to static content
- **Mitigation:** Use structured prompts with strict formats
- **Mitigation:** Implement content filters

### Risk 2: Latency
- **Mitigation:** Cache common descriptions
- **Mitigation:** Async generation (show "thinking..." indicator)
- **Mitigation:** Hybrid mode (AI for important moments only)

### Risk 3: Cost (if using API)
- **Mitigation:** Offer free Ollama mode
- **Mitigation:** Implement token budgets per session
- **Mitigation:** Cache and reuse appropriate content

### Risk 4: Context Drift
- **Mitigation:** Strict context windowing
- **Mitigation:** Periodic "memory compression" summaries
- **Mitigation:** Track essential facts separately

### Risk 5: Breaking Game Balance
- **Mitigation:** AI narrates, engine decides (dice, combat, loot)
- **Mitigation:** Comprehensive testing
- **Mitigation:** AI mode toggle for classic experience

---

## ğŸ“ˆ Success Metrics

### Phase 1
- âœ… 100% chamber descriptions generated successfully
- âœ… <500ms average latency for narration (with caching)
- âœ… 0 game-breaking AI responses
- âœ… All existing tests still pass
- âœ… 39/39 AI storyteller tests passing

### Phase 2
- [ ] NPCs respond coherently 95%+ of the time
- [ ] Quest completion rate >80%
- [ ] Player satisfaction with dialogue (survey)
- [ ] <1000ms average dialogue generation

### Phase 3
- [ ] Player choice tracking 100% accurate
- [ ] Narrative branching functions correctly
- [ ] Session memory persists across reconnects
- [ ] Campaign completion rate >60%

---

## ğŸ”„ Maintenance Plan

### Weekly
- [ ] Monitor API costs (if using paid LLM)
- [ ] Review AI output quality
- [ ] Check error logs for AI failures
- [ ] Update prompt templates based on feedback

### Monthly
- [ ] Retrain/fine-tune prompts
- [ ] Update NPC personalities
- [ ] Add new quest templates
- [ ] Performance optimization

### Quarterly
- [ ] Evaluate new LLM models
- [ ] User feedback survey
- [ ] Content expansion (new NPCs, locations)
- [ ] Major feature additions

---

## ğŸ“š Resources & References

### Documentation to Create
- [ ] `docs/AI_INTEGRATION.md` - Technical integration guide
- [ ] `docs/PROMPT_ENGINEERING.md` - Prompt templates and best practices
- [ ] `docs/AI_TROUBLESHOOTING.md` - Common issues and solutions

### External Resources
- Ollama: https://ollama.com
- OpenAI API: https://platform.openai.com/docs
- Anthropic Claude: https://www.anthropic.com/claude
- LangChain (optional framework): https://www.langchain.com

---

## ğŸ¯ Next Steps

1. **Immediate:** Review and approve roadmap
2. **Week 1:** Implement Phase 1 (AI Narration Layer)
3. **Week 2:** Test and iterate on descriptions
4. **Week 3-4:** Phase 2 (Dynamic NPCs)
5. **Month 2:** Phase 3 (Adaptive Storytelling)

---

## ğŸ’¬ Notes

- Keep game mechanics deterministic (dice, combat, loot)
- AI enhances narrative, doesn't replace core gameplay
- Always provide classic mode fallback
- Focus on player experience over technical complexity
- Iterate based on playtesting feedback

---

**Status:** Ready for Phase 1 implementation  
**Owner:** To be assigned  
**Priority:** High (transforms core gameplay experience)
